\documentclass[11pt,a4paper]{article}
\usepackage{lmodern}

\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{???}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[lmargin=2.5cm,rmargin=2.5cm,tmargin=2.5cm,bmargin=2.5cm]{geometry}

% Figure Placement:
\usepackage{float}
\let\origfigure\figure
\let\endorigfigure\endfigure
\renewenvironment{figure}[1][2] {
    \expandafter\origfigure\expandafter[H]
} {
    \endorigfigure
}

%% citation setup
\usepackage{csquotes}

\usepackage[backend=biber, maxbibnames = 99, style = apa]{biblatex}
\setlength\bibitemsep{1.5\itemsep}
\addbibresource{R_packages.bib}
\bibliography{references.bib}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true, linktocpage = TRUE]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={Alex Amaguaya, Lea Bergmann},
            pdftitle={The Gender Pay Gap in the General Social Survey},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{5}

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{The Gender Pay Gap in the General Social Survey}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
\subtitle{Statistical Learning}
  \author{Alex Amaguaya, Lea Bergmann}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{today}


%% linespread settings

\usepackage{setspace}

\onehalfspacing

% Language Setup

\usepackage{ifthen}
\usepackage{iflang}
\usepackage[super]{nth}
\usepackage[ngerman, english]{babel}

%Acronyms
\usepackage[printonlyused, withpage, nohyperlinks]{acronym}
\usepackage{changepage}

% Multicols for the Title page
\usepackage{multicol}


\usepackage{longtable}

\begin{document}

\selectlanguage{english}


%\maketitle

\begin{titlepage}
  \noindent\begin{minipage}{0.6\textwidth}
	  \IfLanguageName{english}{University of Duisburg-Essen}{Universit\"at Duisburg-Essen}\\
	  \IfLanguageName{english}{Faculty of Business Administration and Economics}{Fakult\"at f\"ur Wirtschaftswissensschaften}\\
	  \IfLanguageName{english}{Chair of Econometrics}{Lehrstuhl f\"ur \"Okonometrie}\\
  \end{minipage}
	\begin{minipage}{0.4\textwidth}
	  \begin{flushright}
  	  \vspace{-0.5cm}
      \IfLanguageName{english}{\includegraphics*[width=5cm]{Includes/duelogo_en.png}}{\includegraphics*[width=5cm]{Includes/duelogo_de.png}}
	  \end{flushright}
	\end{minipage}
  \\
  \vspace{1.5cm}
  \begin{center}
  \huge{The Gender Pay Gap in the General Social Survey}\\
  \vspace{.25cm}
  \Large{Statistical Learning}\\
  \vspace{0.5cm}
  \large{Term Paper}\\
  \vspace{1cm}
  \large{
  \IfLanguageName{english}{Submitted to the Faculty of \\ Business Administration and Economics \\at the \\University of Duisburg-Essen}{Vorgelegt der \\Fakult\"at f\"ur Wirtschaftswissenschaften der \\ Universit\"at Duisburg-Essen}\\}
  \vspace{0.75cm}
  \large{\IfLanguageName{english}{from:}{von:}}\\
  \vspace{0.5cm}
  Alex Amaguaya, Lea Bergmann\\
  \end{center}
  %\vspace{2cm}
  \vfill
  \hrulefill

  \noindent\begin{minipage}[t]{0.3\textwidth}
  \IfLanguageName{english}{Reviewer:}{Erstgutachter:}
  \end{minipage}
  \begin{minipage}[t]{0.7\textwidth}
  \hspace{1cm}
  \end{minipage}

  \noindent\begin{minipage}[t]{0.3\textwidth}
  \IfLanguageName{english}{Deadline:}{Abgabefrist:}
  \end{minipage}
  \begin{minipage}[t]{0.7\textwidth}
  \hspace{1cm}tomorrow
  \end{minipage}

  \hrulefill

  \begin{multicols}{3}

  Name:

  Matriculation No.:

  E-Mail:

  Study Path:

  Semester:

  Graduation (est.):

  \columnbreak

  Ape Monkey

  123456

  Ape@Monkey.biz

  M.Sc. Economics

  \nth{5}

  Summer Term 2020

  \columnbreak

  John Doe

  234567

  john.doe@web.de

  M.Sc. Economics

  \nth{4}

  Summer Term 2020

  \columnbreak

  Darth Vader

  543556

  vader@emperialenterprises.com

  M.Sc. Economics

  \nth{3}

  Summer Term 2020

  \end{multicols}

\end{titlepage}

\newgeometry{top=2cm, left = 5cm, right = 2.5cm, bottom = 2.5cm}


\pagenumbering{Roman}
{
\hypersetup{linkcolor=black}

\setcounter{tocdepth}{3}
\tableofcontents
}

\newpage
\listoffigures
\addcontentsline{toc}{section}{List of Figures}

%\newpage
\listoftables
\addcontentsline{toc}{section}{List of Tables}

\section*{List of Abbreviations}
\addcontentsline{toc}{section}{List of Abbreviations}

\begin{adjustwidth}{1.5em}{0pt}

\begin{acronym}[dummyyyy]
 \acro{ECTSCP}{European Credit Transfer System Credit Point}
 \acro{lasso}{Least Absolute Shrinkage and Selection Operator}
 \acro{pcr}{Principal Components Regression}
 \acro{pls}{Partial Least Squares}
 \acro{RMSE}{Root Mean Squared Error}
 \acroplural{LRG}[LRG]{laengefristige Refinanzierungsgeschaefte}

%Falls eine Abkuerzung in der Mehrzahl nicht einfach auf "s" endet muss das speziell eingestellt werden.
% \acro{slmtA}{super lange mega tolle Abkuerzung} %Einzahl
 %\acroplural{slmtA}[slmtAs]{super lange mega tolle Abkuerzungen} %Mehrzahl
 \acro{dummyyyy}{dummyyy}
\end{acronym}

\end{adjustwidth}

\restoregeometry

\newpage
\pagenumbering{arabic}
\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In this paper we predict individuals' wages using data from the General
Social Survey (GSS, 1974-2018). The variable of interest is
\texttt{realrinc} which varies between 227\$ and
480,145\$\footnote{In constant 1986 USD.}. Hence, we can use regression
techniques to predict individuals' wages. Additionally, we can consider
whether \texttt{realrinc} varies by gender and if so, how much.

The data from the GSS allow us to consider various control variables
such as gender, age, education, occupation, number of children and
marital status.

The prediction of individuals' wages has been an issue in previous
literature. As wages are relevant to companies they want to know how
predict wages \autocite{Chakraborti}. Some papers make use of
classification techniques to predict wages \autocite{Chakraborti}. As we
have numeric values of real wages and not a categorical variable we do
not make use of classification techniques but prefer linear regression
techniques such as OLS and Lasso regressions as well as random forests.
We prefer these techniques as they handle categorical variables and
outliers well, which are features of our data \autocite{Cutler}. Wages
were already predicted using random forests by \autocite{Eichinger}.
They find that using random forests results in better predictions than
using linear models. Additionally, they show that gender barely effects
the wage predictions.

Based on the previous literature, we use several regression techniques
to predict \texttt{realrinc}:

\begin{itemize}
\item
  Linear Regression
\item
  Logistic Regression
\item
  Lasso, Ridge and Elastic Net Regression
\item
  Gradient Boosting
\item
  Random Forest
\end{itemize}

In order to evaluate which of the regression techniques predicts
\texttt{realrinc} the best we split the data set into a train (70\%) and
a test (30\%) data set. We fit the aforementioned regression models on
the train data and evaluate the root mean squared error (RMSE) using the
validation data. We choose the RMSE as it is more sensitive to large
errors \autocite{Arour}.

{[}Write something about cross validation?{]}

\hypertarget{data-preparation-feature-engineering}{%
\section{Data Preparation \& Feature
Engineering}\label{data-preparation-feature-engineering}}

The initial data set contains 11 variables, which are described in the
following: - \textbf{year}: survey year - \textbf{realrinc}:
respondent's base income (in constant 1986 USD) - \textbf{age}:
respondent's age in years - \textbf{occ10}: respondent's occupation code
- \textbf{occrecode}: recode of the occupation code into one of 11 main
categories - \textbf{prestg10}: respondent's occupational prestige score
- \textbf{childs}: number of children - \textbf{wrkstat}: work status of
the respondent (full-time, part-time, temporarily not working,
unemployed (laid off), etc.) - \textbf{gender}: respondent's gender -
\textbf{educcat}: respondent's degree level (Less Than High School, High
School, etc.) - \textbf{maritalcat}: respondent's marital status
(Married, Widowed, Divorced, etc.)

\hypertarget{data-preparation}{%
\subsection{Data Preparation}\label{data-preparation}}

Before modeling we prepared the data. The initial data set has 54,842
observations and the outcome variable \texttt{realrinc} has 38.55\% of
missing values. The imputation of the target variable was discarded to
avoid generating a bias in the modeling and therefore we decided to
eliminate these records from the original data set. After this, the data
set contains 33,702 observations. Furthermore, it was impossible to
deduce the occupation for some observations (\texttt{occ10\ =\ 9997})
and these are removed from the data set. At the end, the final data set
has 33,244 observations, and is used for the modeling process.

This data set still has some missing values for the regressors, e.g.,
number of children, age, marital status, degree level, and others. Using
the \texttt{mice} package we conduct the imputation using five
variables. We impute the features \emph{age, occupational prestige and
number of children} using the pmm (\texttt{predictive\ mean\ matching})
method. The polytomous logistic regression method is used for the factor
variables (\emph{education and marital status}). The imputation process
uses a number of multiple imputations of six. This means that the
imputation process creates 6 different data sets, and then the
estimation of the mean and the majority vote is applied to aggregate the
data sets into a single data set. The mean estimation is applied for
numeric variables and majority vote for categorical variables..

\hypertarget{feature-engineering}{%
\subsection{Feature Engineering}\label{feature-engineering}}

After the imputation process we create interaction variables. First,
some interaction features are estimated using only the numerical
variables, and then we transform the numerical variables into
categorical variables by dividing them into different ranges (e.g.~age
between 18 and 30, age between 31 and 50, etc). These new categorical
variables and the initial categorical variables (\emph{marital status,
education, etc}) are transformed into dummy variables. And finally, we
estimate the interaction variables with the group of dummy variables
mentioned above. We validate the inclusion of the interaction of the
numeric variables using a linear model. The results show that the
p-values of the parameters for the interactions are less than 0.05.

\begin{figure}
\centering
\includegraphics{includes/reg_table.png}
\caption{table}
\end{figure}

Furthermore, we estimate a correlation matrix using Spearman's rank
correlation coefficient with some numeric variables in order to support
the previous results. The correlation results are shown in the following
figure.

\begin{figure}
\centering
\includegraphics{includes/corr_matrix.png}
\caption{matrix\_corr}
\end{figure}

After the data preparation and feature engineering processes, we
construct a final data set with 33,244 observations and 421 features.
Due to the large number of interaction variables, we decided to reduce
them and use only the interaction between a group of variables
(\emph{occrecode, educcat and prestg10}). After reduction, the modeling
process is developed with 100 variables (numerical and interaction
variables). The following figure shows the overview of the group of
variables that we estimated and used in the models.

\begin{figure}
\centering
\includegraphics{includes/feature_process.png}
\caption{feature\_process}
\end{figure}

\hypertarget{model-training-and-tuning}{%
\section{Model Training and Tuning}\label{model-training-and-tuning}}

We use five different regression techniques to predict the individuals'
wages using the final dataset. We fit every model on our training data
using the \texttt{train} function from the \texttt{caret} package. To
choose the best parameter combination we use cross-validation within all
train functions.

\hypertarget{linear-and-logistic-regression}{%
\subsection{Linear and Logistic
Regression}\label{linear-and-logistic-regression}}

Our baseline linear model uses an OLS regression including all
interaction variables. This results in an RMSE of 25,506.05.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula }\OtherTok{\textless{}{-}} \FunctionTok{as.formula}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"realrinc \textasciitilde{}"}\NormalTok{, }\FunctionTok{paste}\NormalTok{(x\_cols\_dummys, }\AttributeTok{collapse =} \StringTok{" + "}\NormalTok{)))}
\NormalTok{mod\_full }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(formula,}
                  \AttributeTok{data =}\NormalTok{ train, }
                  \AttributeTok{method =} \StringTok{"lm"}\NormalTok{,  }
                  \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Given some extreme outliers in the income distribution of our data
(which is typical for wage data) we follow the economic literature
\autocite{Ermini} and fit a logistic model to our data, using the log of
\texttt{realrinc} as our dependent variable. This results in a higher
RMSE than the linear model (25,909.82).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula2 }\OtherTok{\textless{}{-}} \FunctionTok{as.formula}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"log\_realrinc \textasciitilde{}"}\NormalTok{, }\FunctionTok{paste}\NormalTok{(x\_cols\_dummys, }\AttributeTok{collapse =} \StringTok{" + "}\NormalTok{)))}
\NormalTok{mod\_loginc }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(formula2,}
                    \AttributeTok{data =}\NormalTok{ train, }
                    \AttributeTok{method =} \StringTok{"lm"}\NormalTok{,  }
                    \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

In both models the coefficient of female is statistically significant
with p \textless{} 0.001. It suggests that being female decreases the
real income by approximately 10,192\$ in the linear model or by 40\% in
the logistic model.

\hypertarget{subset-selection}{%
\subsection{Subset Selection}\label{subset-selection}}

As the dataset contains many variables (361) and even our selection of
dummy variables for the right-hand side of the regression leaves us with
53 variables, we make use of regression techniques for subset selection.
We use lasso, ridge and elastic net regressions. These methods allow us
to fit a model that contains all variables. Then the model regularizes
the coefficient estimates and shrinks them towards zero. In effect, we
reduce the estimates' variance which improves the model fit.

We start with a ridge regression.

\[
RSS + \lambda \sum^p _{j=1} \beta^2_j 
\]

Hence, the coefficient estimates in a ridge regression minimize the sum
of the residual sum of squares (RSS) and the sum of squared coefficients
multiplied with a tuning parameter \(\lambda\). We estimate \(\lambda\)
using cross-validation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ridge }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(formula, }\AttributeTok{data =}\NormalTok{ train,}
  \AttributeTok{method =} \StringTok{"glmnet"}\NormalTok{, }\AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{),}
  \AttributeTok{tuneGrid =} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{0}\NormalTok{, }\AttributeTok{lambda =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{1}\NormalTok{))) }
\end{Highlighting}
\end{Shaded}

Perform a ridge regression to predict real incomes yields an RMSE of
25,524.85.

In contrast to other subset selection methods ridge regression does not
exclude any variables from the regression model. Hence, the model is
still fitted on 53 covariates. To overcome this issue we also use a
lasso regression.

\[
RSS + \lambda \sum^p_{j=1} | \beta_j |
\]

In contrast to the ridge regression the lasso regression forces some of
the coefficient estimates to be equal to zero if \(\lambda\) is
sufficiently large. Hence, the regression is not performed on all
covariates.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lasso }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(formula, }\AttributeTok{data =}\NormalTok{ train, }
       \AttributeTok{method =} \StringTok{"glmnet"}\NormalTok{, }\AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{), }
       \AttributeTok{tuneGrid =} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{lambda =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{500}\NormalTok{,}\DecValTok{1}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

To perform the lasso regression in \texttt{R} we set \(\alpha\) equal to
one. The lasso regression yields a lower RMSE than the ridge regression
(25,504.58 vs.~25,524.85) and even a lower RMSE than the linear
regression.

In a final step we use elastic net regularization which is a linear
combination of ridge and lasso regression. The elastic net
regularization allows \(\alpha\) to vary between zero and one. This
results in an RMSE of 25,241.7.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elasticnet }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(formula, }\AttributeTok{data =}\NormalTok{ train,}
       \AttributeTok{method =} \StringTok{"glmnet"}\NormalTok{, }\AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{),}
       \AttributeTok{tuneGrid =} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{alpha =} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from=}\DecValTok{0}\NormalTok{, }\AttributeTok{to=}\DecValTok{1}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.1}\NormalTok{),}
       \AttributeTok{lambda =} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from=}\DecValTok{0}\NormalTok{, }\AttributeTok{to=}\FloatTok{0.15}\NormalTok{, }\AttributeTok{by =} \FloatTok{0.001}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}


\end{document}